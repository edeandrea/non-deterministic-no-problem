quarkus:
  # Default LangChain4j configuration
  langchain4j:
    parasol-chat:
      chat-model:
        provider: openai
    embedding-model:
      provider: openai
    log-requests: true
    log-responses: true

    # RAG
    easy-rag:
      path: src/main/resources/policies
      reuse-embeddings:
        enabled: true

    # OpenAI
    openai:
      api-key: "${OPENAI_API_KEY}"
      parasol-chat:
        chat-model:
          temperature: 0.3
        timeout: 600s
        api-key: "${quarkus.langchain4j.openai.api-key}"
      generate-email:
        chat-model:
          temperature: 0.3
        timeout: 600s
        api-key: "${quarkus.langchain4j.openai.api-key}"
      politeness:
        chat-model:
          temperature: 0.3
        timeout: 600s
        api-key: "${quarkus.langchain4j.openai.api-key}"

    # Milvus
    milvus:
      dimension: 1536

    # Ollama
    ollama:
      parasol-chat:
        timeout: 600s
        chat-model:
          model-id: llama3.2
          temperature: 0.3
      generate-email:
        timeout: 600s
        chat-model:
          model-id: llama3.2
          temperature: 0.3
      politeness:
        timeout: 600s
        chat-model:
          model-id: llama3.2
          temperature: 0.3
      embedding-model:
        model-id: snowflake-arctic-embed

  # Mail
  mailer:
    tls: false

  # HTTP
  http:
    cors:
      ~: true
      origins: '*'
  dev-ui:
    cors:
      enabled: true
  tls:
    trust-all: true

  # Hibernate
  hibernate-orm:
    physical-naming-strategy: org.hibernate.boot.model.naming.CamelCaseToUnderscoresNamingStrategy

  # Quinoa
  quinoa:
    build-dir: dist
    enable-spa-routing: true
    package-manager-install:
      ~: true
      node-version: 22.12.0
      npm-version: 10.9.2

  # Websockets
  websockets-next:
    server:
      auto-ping-interval: 1m

  # OpenTelemetry and tracing
  otel:
    logs:
      enabled: true
    metrics:
      enabled: true
  datasource:
    jdbc:
      telemetry: true

# Ollama profile config
'%ollama':
  quarkus:
    langchain4j:
      parasol-chat:
        chat-model:
          provider: ollama
      generate-email:
        chat-model:
          provider: ollama
      politeness:
        chat-model:
          provider: ollama
      embedding-model:
        provider: ollama
      milvus:
        dimension: 1024

# Ollama using OpenAI endpoint profile config
'%ollama-openai':
  quarkus:
    langchain4j:
      openai:
        base-url: http://localhost:11434/v1
        parasol-chat:
          base-url: "${%ollama-openai.quarkus.langchain4j.openai.base-url}"
          chat-model:
            model-name: "${quarkus.langchain4j.ollama.parasol-chat.chat-model.model-id}"
        generate-email:
          base-url: "${%ollama-openai.quarkus.langchain4j.openai.base-url}"
          chat-model:
            model-name: "${quarkus.langchain4j.ollama.parasol-chat.chat-model.model-id}"
        politeness:
          base-url: "${%ollama-openai.quarkus.langchain4j.openai.base-url}"
          chat-model:
            model-name: "${quarkus.langchain4j.ollama.parasol-chat.chat-model.model-id}"
        embedding-model:
          model-name: "${quarkus.langchain4j.ollama.embedding-model.model-id}"
      milvus:
        dimension: 1024

# Dev mode config
'%dev':
  quarkus:
    mailer:
      mock: false

# Dev and test modes config
'%dev,test':
  quarkus:
    log:
      category:
        'org.parasol':
          level: DEBUG
      console:
        level: DEBUG

# test mode config
'%test':
  quarkus:
    otel:
      logs:
        enabled: false
    observability:
      enabled: false
    micrometer:
      export:
        otlp:
          enabled: "${%test.quarkus.observability.enabled}"

# Prod mode config
'%prod':
  quarkus:
    hibernate-orm:
      database:
        database:
          generation: drop-and-create
      sql-load-script: import.sql